{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rk-wJshZrKtw"
   },
   "source": [
    "# Mentoring 1 - Introduction to Machine Learning\n",
    "---\n",
    "\n",
    "Mentoring Session - Job Preparation Program - Pacmann AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0le3bfkbsWCu"
   },
   "source": [
    "## Instructions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6NAWntWqu6Bu"
   },
   "source": [
    "1. Please fill all the given tasks in here\n",
    "2. You can use any library\n",
    "3. For modeling, please use `sklearn` library\n",
    "4. You are taksed to create a function based machine learning model. (If you cannot create the functions from the start, you can create without a function first, then put it all into a function)\n",
    "5. Make sure you are following all the function descriptions\n",
    "6. Submit your result to the submission form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VF3H55TwV1f"
   },
   "source": [
    "## Dataset Description\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm47UzYPwY1h"
   },
   "source": [
    "**Note**\n",
    "\n",
    "- This dataset originally comes from [Uber Fares Dataset](https://www.kaggle.com/datasets/yasserh/uber-fares-dataset)\n",
    "- We perform several edit for this mentoring purposes. So, please use the dataset from [here](https://drive.google.com/file/d/1-Fr3OMbI1yKU_jNy-6cgXFJDVzjph3sn/view?usp=sharing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTVZoo2jw2mv"
   },
   "source": [
    "**Description**\n",
    "- We're looking to predict the fare of Uber's transactions.\n",
    "- The dataset contains of the following fields\n",
    "\n",
    "<center>\n",
    "\n",
    "|Feature|Type|Descriptions|\n",
    "|:--|:--|:--|\n",
    "|`order_id`| `int` | a unique identifier for each trip|\n",
    "|`pickup_time` | `str` | a class of pickup time. `04-10`, `10-16`, `16-22`, `22-04`. E.g. `04-10` means the pickup time is between 04.00 to 10.00|\n",
    "| `pickup_longitude` | `float` | the longitude where the meter was engaged|\n",
    "| `pickup_latitude` | `float` | the latitude where the meter was engaged|\n",
    "| `dropoff_longitude` | `float` | the longitude where the meter was disengaged|\n",
    "| `dropoff_latitude` | `float` | the latitude where the meter was disengaged|\n",
    "| `passenger_count` | `float` | the number of passengers in the vehicle (driver entered value)|\n",
    "| `fare_amount` | `int` | the cost of each trip in USD, (**our target**)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPfdLquFzsoI"
   },
   "source": [
    "## Modeling Workflow\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBa9dq-Rsxak"
   },
   "source": [
    "```\n",
    "1. Import data to Python\n",
    "2. Data Preprocessing\n",
    "3. Training a Machine Learning Models\n",
    "4. Test Prediction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x_OE7Mklz1Ci"
   },
   "source": [
    "### 1. Import data to Python (10 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r6Yb-EssUkX"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Import Numpy and Pandas library\n",
    "# Write your code here\n",
    "####################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "773jxJ0P0IAq"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create a function named read_data\n",
    "# - Has an input of filename, i.e. fname\n",
    "# - Read the data as a Pandas DataFrame\n",
    "# - Drop duplicate on `order_id`, keep the last ones\n",
    "# - Set `order_id` as index\n",
    "# - Print the data shape\n",
    "# - Return the dataset\n",
    "# Write your code here\n",
    "####################################################\n",
    "def read_data(fname):\n",
    "    \"\"\"\n",
    "    Read and preprocess the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - fname (str): The filename of the dataset to be read.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: The processed dataset.\n",
    "    \"\"\"\n",
    "    with open(fname, 'r') as f: \n",
    "        df = pd.read_csv(f, sep=',', header=0)\n",
    "        print(f'Data shape rawd: {df.shape}')\n",
    "\n",
    "        # Drop duplicate on `order_id`, keep the last ones\n",
    "        # Set `order_id` as index\n",
    "        df = df.drop_duplicates(subset='order_id', keep='last') \n",
    "        df_count_dup = df.duplicated(subset='order_id').sum()\n",
    "        print(f'Number of duplicate order id: {df_count_dup}')\n",
    "        print(f'Data shape after dropping: {df.shape}')\n",
    "        \n",
    "        df =df.set_index('order_id', inplace=False)\n",
    "        print(f'Data shape final: {df.shape}')\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFRDR1I-1aDe",
    "outputId": "35c83b27-efd1-4f7f-da34-fc72abad7257"
   },
   "outputs": [],
   "source": [
    "# Read the Uber data (JUST RUN THE CODE)\n",
    "data = read_data(fname='uber_edit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "N8eIfaVU3QJS",
    "outputId": "ba5a6b3e-d60d-4bc5-9585-a6df87bc9b4d"
   },
   "outputs": [],
   "source": [
    "# JUST RUN THE CODE\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OzWPGFk3iwl"
   },
   "source": [
    "### 2. Data Preprocessing (60 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XP-LVEz8MmLe"
   },
   "source": [
    "**The processing pipeline**\n",
    "```\n",
    "2.1 Input-Output Split\n",
    "2.2 Train-Valid-Test Split\n",
    "2.3 Separate Numerical and Categorical Features\n",
    "2.4 Numerical Imputation\n",
    "2.5 Categorical Imputation\n",
    "2.6 Preprocess Categorical Features\n",
    "2.7 Join the Data\n",
    "2.8 Feature Engineering the Data\n",
    "2.9 Create a Preprocessing Function\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPzQ-1Wz3lgP"
   },
   "source": [
    "#### 2.1. Input-Output Split (6 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0eNiv8J3ogi"
   },
   "source": [
    "- We're going to split input & output according to the modeling objective.\n",
    "- Create a function to split the input & output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7JLABNi-3ktA"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create a function named split_input_output\n",
    "# - Has two arguments\n",
    "#   - data, a pd Dataframe\n",
    "#   - target_col, a column (str)\n",
    "# - Print the data shape after splitting\n",
    "# - Return X, y\n",
    "# Write your code here\n",
    "####################################################\n",
    "def split_input_output(data, target_col):\n",
    "    \"\"\"\n",
    "    Splits the input data into features (X) and target (y).\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input dataset.\n",
    "    - target_col (str): The name of the target column.\n",
    "\n",
    "    Returns:\n",
    "    - X (pd.DataFrame): The feature columns.\n",
    "    - y (pd.Series): The target column.\n",
    "    \"\"\"\n",
    "    X = data.drop(columns=[target_col])\n",
    "    y = data[target_col]\n",
    "    print(f'X shape: {X.shape}')\n",
    "    print(f'y shape: {y.shape}')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oN8Kuzkf4hgN",
    "outputId": "a2dcb8dc-7508-4a67-dae1-c07244bf3485"
   },
   "outputs": [],
   "source": [
    "# Load the train data only (JUST RUN THE CODE)\n",
    "X, y = split_input_output(data=data,\n",
    "                          target_col='fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ScJnHQsZ45Lf",
    "outputId": "8999f793-e31c-48ae-dc22-6d2c92844543"
   },
   "outputs": [],
   "source": [
    "X.head()  # (JUST RUN THE CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvvwO3A547u1",
    "outputId": "fa95702d-7c15-40e3-8c19-7364e11fec4a"
   },
   "outputs": [],
   "source": [
    "y.head()  # (JUST RUN THE CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO3YDDwc5qQ-"
   },
   "source": [
    "#### 2.2. Train-Valid-Test Split (6 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFA5PsKQ5qRN"
   },
   "source": [
    "- Now, we want to split the data before modeling.\n",
    "- Split the data into three set:\n",
    "  - Train, for training the model\n",
    "  - Validation, for choosing the best model\n",
    "  - Test, for error generalization\n",
    "\n",
    "- You should make the splitting proportion train (80%), valid (10%), and test (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LTodPoF5qRN"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create a function named split_train_test\n",
    "# - Has two arguments\n",
    "#   - X, the input (pd.Dataframe)\n",
    "#   - y, the output (pd.Dataframe)\n",
    "#   - test_size, the test size between 0-1 (float)\n",
    "#   - seed, the random state (int)\n",
    "# - Print the data shape after splitting\n",
    "# - Return X_train, X_test, y_train, y_test\n",
    "# - You can use an sklearn library to help you\n",
    "# Write your code here\n",
    "####################################################\n",
    "def split_train_test(X, y, test_size, seed):\n",
    "    \"\"\"\n",
    "    Split the input data (X) and target data (y) into train and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): The input features.\n",
    "    - y (pd.DataFrame or pd.Series): The target labels.\n",
    "    - test_size (float): The proportion of the dataset to include in the test split (0-1).\n",
    "    - seed (int): The random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - X_train (pd.DataFrame): Training input data.\n",
    "    - X_test (pd.DataFrame): Testing input data.\n",
    "    - y_train (pd.DataFrame or pd.Series): Training output data.\n",
    "    - y_test (pd.DataFrame or pd.Series): Testing output data.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "        \n",
    "    print(f'X train shape: {X_train.shape}')\n",
    "    print(f'y train shape: {y_train.shape}')\n",
    "    print(f'X test shape : {X_test.shape}')\n",
    "    print(f'y test shape : {y_test.shape}\\n')\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1F6TPylm49KB",
    "outputId": "63fed923-a3a5-4288-b12b-114f6b1f81cf"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# First, split the train & not train\n",
    "X_train, X_not_train, y_train, y_not_train = split_train_test(X, y, test_size=0.2, seed=123) # WRITE YOUR CODE HERE, Use seed=123\n",
    "\n",
    "# Then, split the valid & test\n",
    "X_valid, X_test, y_valid, y_test = split_train_test(X_not_train, y_not_train, test_size=0.5, seed=123) # WRITE YOUR CODE HERE, Use seed=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4gTzpb627pJB",
    "outputId": "d1a3a905-4ed5-4dea-b087-bef5575678f5"
   },
   "outputs": [],
   "source": [
    "# Validate (JUST RUN THE CODE)\n",
    "print(len(X_train)/len(X))  # should be 0.8\n",
    "print(len(X_valid)/len(X))  # should be 0.1\n",
    "print(len(X_test)/len(X))   # should be 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6GgKZ5Z-d-A",
    "outputId": "8c051c7d-b561-4ded-e230-b16deafed4e9"
   },
   "outputs": [],
   "source": [
    "X_train.head()  # (JUST RUN THE CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ5rwYBA88lQ"
   },
   "source": [
    "#### 2.3. Separate Numerical and Categorical Features (6 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaRGC1IJ88lU"
   },
   "source": [
    "- We now prepare to perform data preprocessing\n",
    "- But, we first separate the data into numerical data & categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTNHnHRi899V"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create a function to split numerical & categorical input\n",
    "# - you have three parameters\n",
    "#   - data, an input data (pd. Dataframe)\n",
    "#   - num_cols, a list of numerical columns (list)\n",
    "#   - cat_cols, a list of categorical columns (list)\n",
    "# - and write a validation that you perform right operation\n",
    "# - and return two dataframe, numerical & categorical data\n",
    "# Write your code here\n",
    "####################################################\n",
    "def split_num_cat(data, num_cols,cat_cols):\n",
    "    \"\"\"\n",
    "    Split the input DataFrame into numerical and categorical DataFrames based on the provided lists of columns.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pd.DataFrame, the input data.\n",
    "    - num_cols: list, a list of numerical columns.\n",
    "    - cat_cols: list, a list of categorical columns.\n",
    "\n",
    "    Returns:\n",
    "    - numerical_cols: pd.DataFrame.\n",
    "    - categorical_cols: pd.DataFrame.\n",
    "    \"\"\"\n",
    "    # Validate that the input columns exist in the DataFrame\n",
    "    for col in num_cols + cat_cols:\n",
    "        if col not in data.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in the input DataFrame.\")\n",
    "\n",
    "    # Validate that there is no overlap between numerical and categorical columns\n",
    "    overlap = set(num_cols).intersection(set(cat_cols))\n",
    "    if overlap:\n",
    "        raise ValueError(f\"Columns {overlap} are present in both numerical and categorical lists.\")\n",
    "\n",
    "    # Split the data into numerical and categorical DataFrames\n",
    "    numerical_cols = data[num_cols]\n",
    "    categorical_cols = data[cat_cols]\n",
    "\n",
    "    print(f'Data num shape: {numerical_cols.shape}')\n",
    "    print(f'Data cat shape: {categorical_cols.shape}')\n",
    "    \n",
    "    return numerical_cols, categorical_cols\n",
    "\n",
    "num_cols = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']\n",
    "cat_cols = ['pickup_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYkiongB-muK",
    "outputId": "56a8f4a3-9199-49fe-b6ab-d325175d7d64"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train_num, X_train_cat = split_num_cat(X_train, num_cols, cat_cols) # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6qd1II0a-0og",
    "outputId": "0e585e71-4234-44df-d84f-0651d69efe5d"
   },
   "outputs": [],
   "source": [
    "X_train_num.head()  # (JUST RUN THE CODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5A8MyYk_Jh7",
    "outputId": "a317fbeb-39bf-478e-9fb3-982b87de6abf"
   },
   "outputs": [],
   "source": [
    "X_train_cat.head()  # (JUST RUN THE CODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSolzD9z_NOc"
   },
   "source": [
    "#### EDA before Preprocessing (JUST RUN THE CODE)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nt7Wtjmk_NOc"
   },
   "source": [
    "- Find the number of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9TN_UpNwAmUD",
    "outputId": "84ff90a4-817f-4fa2-8d23-2c1d9dabda63"
   },
   "outputs": [],
   "source": [
    "100 * (X_train.isna().sum(0) / len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CmEIM19Aqnr"
   },
   "source": [
    "- We will impute all these variables if there is any missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBVeQTSaDtdO"
   },
   "source": [
    "- First, check the numerical features distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cDPzHlriAFck"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "eOXpnmQc_NOc",
    "outputId": "ce3be5d4-9e74-485f-fdc7-cb78e1e5ab6e"
   },
   "outputs": [],
   "source": [
    "# Plot histogram\n",
    "fig, ax = plt.subplots(nrows=3, ncols=2, figsize=(12, 8))\n",
    "axes = ax.flatten()\n",
    "\n",
    "for i, col in enumerate(X_train_num.columns):\n",
    "    sns.kdeplot(X_train_num[col], ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYreWROVFMos"
   },
   "source": [
    "- All the distribution are skewed, we can impute a missing value by its features median."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7TnRAdkFWiT"
   },
   "source": [
    "- Next, explore the `pickup_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8c9PHjaFUrv",
    "outputId": "0326f3a2-f904-4cbe-d315-3de79009d9be"
   },
   "outputs": [],
   "source": [
    "X_train['pickup_time'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bEMsSiSG6NZ"
   },
   "source": [
    "- There's a missing value with symbol `'-'` in `pickup_time`,\n",
    "- We can impute the missing value with `UNKNOWN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OX5MqqWjHEbg"
   },
   "source": [
    "- Explore the relation between `pickup_time` and `fare`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "xqg-kjr-GvYf",
    "outputId": "94bef63f-7107-4bcb-c336-869d09f9af49"
   },
   "outputs": [],
   "source": [
    "# Concat the data first\n",
    "train_data = pd.concat((X_train, y_train), axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "e0xMJc-oHO8m",
    "outputId": "3a822bbd-4d15-4c07-8513-fb972ef08008",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a boxplot\n",
    "sns.boxplot(data=train_data[train_data['fare_amount'] < 50],\n",
    "            x='pickup_time',\n",
    "            y='fare_amount')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcqYxsDtHynL"
   },
   "source": [
    "- There is no significant fare different between `pickup_time`.\n",
    "- We can perform a one hot encoding for this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vXXNcIuH86Y"
   },
   "source": [
    "**Conclusion for preprocessing**\n",
    "- Impute the missing `passenger_counts` with its median\n",
    "- Impute the missing `pickup_time` with `'UNKNOWN'`\n",
    "- Feature engineering the `dropoff` and `pickup` coordinate to be a distance between pickup and dropoff. We can use an Euclidean distance for simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUARDkuwIm7D"
   },
   "source": [
    "#### 2.4. Numerical Imputation (6 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "squyrSVbJ5dc"
   },
   "source": [
    "- Now, let's perform a numerical imputation\n",
    "- First check the missing value of the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVMwSr35MyCf",
    "outputId": "5538a4bb-49d5-4d0c-df10-805639492641"
   },
   "outputs": [],
   "source": [
    "# Check missing value (JUST RUN THE CODE)\n",
    "X_train_num.isna().sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qli0bc7TIm7H"
   },
   "source": [
    "- Create a function to fit a numerical features imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9xCqY1vIm7I"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create function to fit & transform numerical imputers\n",
    "# The fit function is called by num_imputer_fit\n",
    "# - it needs 1 input, the data (pd.DataFrame)\n",
    "# - the missing value is np.nan\n",
    "# - the imputation strategy is median\n",
    "# - it return the imputer\n",
    "#\n",
    "# The transform function is called by num_imputer_transform\n",
    "# - it needs 2 input, data (pd.DataFrame) and imputer (sklearn object)\n",
    "# - it return the imputed data in pd.DataFrame format\n",
    "#\n",
    "# Write your code here\n",
    "####################################################\n",
    "def num_imputer_fit(data):\n",
    "    \"\"\"\n",
    "    Fit a numerical imputer.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing numerical data.\n",
    "        \n",
    "    Returns:\n",
    "    - SimpleImputer: The fitted imputer.\n",
    "    \"\"\"\n",
    "    \n",
    "    fit_data = SimpleImputer(strategy='median').fit(data)\n",
    "\n",
    "    return fit_data\n",
    "\n",
    "def num_imputer_transform(data, imputer):\n",
    "    \"\"\"\n",
    "    Transform the numerical data using a fitted imputer.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing numerical data.\n",
    "    - imputer (SimpleImputer): The fitted imputer.\n",
    "        \n",
    "    Returns:\n",
    "    - pd.DataFrame: The DataFrame with imputed values.\n",
    "    \"\"\"\n",
    "    transform_data = pd.DataFrame(imputer.transform(data),\n",
    "                                  columns=data.columns, index=data.index)\n",
    "\n",
    "    return transform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k3-99ZrM1-uU"
   },
   "source": [
    "- Perform imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6M8Ea7ybH7B3"
   },
   "outputs": [],
   "source": [
    "# Get the numerical imputer\n",
    "num_imputer = num_imputer_fit(X_train_num) # WRITE YOUR CODE HERE\n",
    "\n",
    "# Transform the data\n",
    "X_train_num_imputed = num_imputer_transform(X_train_num, num_imputer) # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkI8me6a2GNN",
    "outputId": "a25aff2c-8bed-4b2c-c724-84c58c6c8a0f"
   },
   "outputs": [],
   "source": [
    "# Validate (JUST RUN THE CODE)\n",
    "X_train_num_imputed.isna().sum(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIqhlTq42cDa"
   },
   "source": [
    "Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1dyVifNK2fZA"
   },
   "source": [
    "#### 2.5. Categorical Imputation (6 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtw3ZtuVMBFq"
   },
   "source": [
    "- Next, let's perform the categorical imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YOLY-j9c2fZN",
    "outputId": "6d8c602c-5e55-4f82-f678-d7bfe2e5ac63"
   },
   "outputs": [],
   "source": [
    "# Check missing value (JUST RUN THE CODE)\n",
    "X_train_cat.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eeKkHCph2fZN"
   },
   "source": [
    "- Create a function to fit a categorical features imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zj32QoP72fZO"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create function to fit & transform categorical imputers\n",
    "# The fit function is called by cat_imputer_fit\n",
    "# - it needs 1 input, the data (pd.DataFrame)\n",
    "# - the missing value is '-'\n",
    "# - the imputation strategy is filling it with 'UNKNOWN'\n",
    "# - it return the imputer\n",
    "#\n",
    "# The transform function is called by cat_imputer_transform\n",
    "# - it needs 2 input, data (pd.DataFrame) and imputer (sklearn object)\n",
    "# - it return the imputed data in pd.DataFrame format\n",
    "#\n",
    "# Write your code here\n",
    "####################################################\n",
    "def cat_imputer_fit(data):\n",
    "    \"\"\"\n",
    "    Fits a SimpleImputer for categorical variables.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Input data containing categorical variables\n",
    "    \n",
    "    Returns:\n",
    "    - SimpleImputer: Fitted imputer object\n",
    "    \"\"\"\n",
    "    fit_data = SimpleImputer(missing_values='-',\n",
    "                             strategy='constant',\n",
    "                             fill_value='UNKNOWN')\n",
    "    fit_data.fit(data)\n",
    "    \n",
    "    return fit_data\n",
    "\n",
    "def cat_imputer_transform(data, imputer):\n",
    "    \"\"\"\n",
    "    Transforms data using a fitted categorical imputer.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Input data to transform\n",
    "    - imputer (SimpleImputer): Fitted imputer object\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Transformed data with imputed values\n",
    "    \"\"\"\n",
    "    imputed_data = imputer.transform(data)\n",
    "    transform_data = pd.DataFrame(imputed_data,\n",
    "                                  columns=data.columns, \n",
    "                                  index=data.index)\n",
    "\n",
    "    return transform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaIpEyAb2fZO"
   },
   "source": [
    "- Perform imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RVqvHaa2fZP"
   },
   "outputs": [],
   "source": [
    "# Perform categorical imputation\n",
    "cat_imputer = cat_imputer_fit(X_train_cat) # WRITE YOUR CODE HERE\n",
    "\n",
    "# Transform\n",
    "X_train_cat_imputed = cat_imputer_transform(X_train_cat, cat_imputer) # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cl1KZpCP2fZP",
    "outputId": "dafd6a60-17fb-459b-f603-59f12d9885d6"
   },
   "outputs": [],
   "source": [
    "# Validate (JUST RUN THE CODE)\n",
    "X_train_cat_imputed.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVbiQF7V2fZP"
   },
   "source": [
    "Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICQiqto83TQ9"
   },
   "source": [
    "#### 2.6. Preprocess Categorical Features (6 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60X9R4Ny3cwY"
   },
   "source": [
    "- We will create a one-hot-encoder (read the `EDA before processing`) for the categorical features\n",
    "- Create a function to perform a one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsly5zI_3TQ_"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Write two functions to perform OHE for the categorical data\n",
    "# The first function is called cat_encoder_fit\n",
    "# - It needs 1 input, the data (pd.DataFrame)\n",
    "# - You create an encoder (from OHE Sklearn)\n",
    "# - input all categories of the categorical data\n",
    "# - if there is other category outside the categories listed right now, ignore it\n",
    "# - return the encoder\n",
    "#\n",
    "# The second function is called cat_encoder_transfrom\n",
    "# - It needs two input, the data (pd.DataFrame), the encoder (sklearn object)\n",
    "# - It transform the input data based on the encoder\n",
    "# - It returns the encoded data (pd.DataFrame)\n",
    "#\n",
    "# Write your code here\n",
    "####################################################\n",
    "def cat_encoder_fit(data):\n",
    "    \"\"\"\n",
    "    Fit a OneHotEncoder for categorical data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing categorical data.\n",
    "        \n",
    "    Returns:\n",
    "    - OneHotEncoder: The fitted encoder.\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    fit_data = encoder.fit(data[['pickup_time']])\n",
    "\n",
    "    return fit_data\n",
    "\n",
    "def cat_encoder_transform(data, encode):\n",
    "    \"\"\"\n",
    "    Transform the categorical data using a fitted encoder.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input DataFrame containing categorical data.\n",
    "    - encode (OneHotEncoder): The fitted encoder.\n",
    "        \n",
    "    Returns:\n",
    "    - pd.DataFrame: The transformed data as a DataFrame.\n",
    "    \"\"\"\n",
    "    encoder = encode\n",
    "    encoded = encoder.transform(data)\n",
    "    transform_data = pd.DataFrame(encoded, columns=encoder.categories_[0])\n",
    "    transform_data.index = data.index\n",
    "        \n",
    "    return transform_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYa06kxt3TQ_"
   },
   "source": [
    "- Perform imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xu_VB3_w3TQ_"
   },
   "outputs": [],
   "source": [
    "# Perform categorical imputation\n",
    "cat_encoder = cat_encoder_fit(X_train_cat_imputed) # WRITE YOUR CODE HERE\n",
    "\n",
    "# Transform\n",
    "X_train_cat_encoded = cat_encoder_transform(X_train_cat_imputed, cat_encoder) # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCjWwE6rN4lt",
    "outputId": "2ad1c38f-f8d5-4d2e-a937-50e20c9d90d2"
   },
   "outputs": [],
   "source": [
    "# Validate  (JUST RUN THE CODE)\n",
    "print('Original shape:', X_train_cat_imputed.shape)\n",
    "print('Encoded shape :', X_train_cat_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TuWmwru63TQ_",
    "outputId": "96b37ffc-1d23-43c8-d626-2c117dd8b686"
   },
   "outputs": [],
   "source": [
    "# Validate  (JUST RUN THE CODE)\n",
    "X_train_cat_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKwZYDhl7IiF",
    "outputId": "2d6b349a-3a4e-4eca-8cfa-4841e271872d"
   },
   "outputs": [],
   "source": [
    "# Validate  (JUST RUN THE CODE)\n",
    "X_train_cat_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGS9Q4vP3TQ_"
   },
   "source": [
    "Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e4PGfH5-7QRM"
   },
   "source": [
    "#### 2.7. Join the data (6 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-MBNC397QRU"
   },
   "source": [
    "- After all the data is filled (numerically), we can join the data\n",
    "- Create a function to join the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdZ4oOas7QRU"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create a function to join / concat the data\n",
    "# The function is called by concat_data\n",
    "# - It needs two input, num_data (pd.DataFrame) and cat_data (pd.DataFrame)\n",
    "# - Don't forget to validate your process\n",
    "# - It returns the concated data\n",
    "#\n",
    "# Write your code here\n",
    "####################################################\n",
    "def concat_data(num_data, cat_data):\n",
    "    \"\"\"\n",
    "    Concatenate numerical and categorical data.\n",
    "    \n",
    "    Parameters:\n",
    "    - num_data (pd.DataFrame): DataFrame containing numerical data.\n",
    "    - cat_data (pd.DataFrame): DataFrame containing categorical data.\n",
    "        \n",
    "    Returns:\n",
    "    - pd.DataFrame: Concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    concated_data = pd.concat([num_data, cat_data], axis=1)\n",
    "    \n",
    "    print(f'Numerical data shape  : {num_data.shape}')\n",
    "    print(f'Categorical data shape: {cat_data.shape}')\n",
    "    print(f'Concat data shape     : {concated_data.shape}')\n",
    "\n",
    "    return concated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apDQ_ZBh7QRV"
   },
   "source": [
    "- Perform concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNXOjIzf7QRV",
    "outputId": "cfcd004f-0895-4cbe-c0e0-07209805806d"
   },
   "outputs": [],
   "source": [
    "# Concat the data\n",
    "X_train_concat = concat_data(X_train_num_imputed, X_train_cat_encoded) # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lx5Un4WZOh3-",
    "outputId": "87e6fde2-5872-4750-f788-953dab7de612"
   },
   "outputs": [],
   "source": [
    "# Validate (JUST RUN THE CODE)\n",
    "X_train_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKaeyh8J7QRW"
   },
   "source": [
    "Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VD93lAeX8ktW"
   },
   "source": [
    "#### 2.8. Feature engineering the data (8 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSlPHShB8kte"
   },
   "source": [
    "- Now, `pickup` and `dropoff` coordinate is not an explicit features.\n",
    "- We can create a better feature called by `distance` to summarize the `pickup` and `dropoff` coordinate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCdNLObo8ktf"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create a function that obtain the distance\n",
    "# The function is called with map_distance\n",
    "# - It needs an input, data (pd.DataFrame)\n",
    "# - In the input, you calculate the trip distance using Euclidean Distance\n",
    "#   ref: https://www.cuemath.com/euclidean-distance-formula/\n",
    "# - Then, you can save the distance information as a new column, 'distance'\n",
    "# - And you can drop the pickup and dropoff latitude and longitude\n",
    "# - You return the mapped data\n",
    "#\n",
    "# Write your code here\n",
    "####################################################\n",
    "def map_distance(data):\n",
    "    \"\"\"\n",
    "    Calculate the Euclidean distance between pickup and dropoff points\n",
    "    and add it as a new column. Drop latitude and longitude columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): DataFrame containing latitude and longitude information. \n",
    "                Must include columns: 'pickup_latitude', 'pickup_longitude', \n",
    "                'dropoff_latitude', 'dropoff_longitude'.\n",
    "            \n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with a new column 'distance' and without latitude/longitude columns.\n",
    "    \"\"\"\n",
    "    data['distance'] = np.sqrt(\n",
    "        (data['dropoff_latitude'] - data['pickup_latitude'])**2 +\n",
    "        (data['dropoff_longitude'] - data['pickup_longitude'])**2\n",
    "    )\n",
    "\n",
    "    data.drop(columns=['dropoff_latitude','pickup_latitude','dropoff_longitude','pickup_longitude'], inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iutgjQ4E8ktf"
   },
   "source": [
    "- Perform distance calculation (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EyO-ke28ktf",
    "outputId": "379b32ba-1f8d-4bd3-df31-bb86efbdd90c"
   },
   "outputs": [],
   "source": [
    "# Calculate the distance\n",
    "X_train_concat_fe = map_distance(X_train_concat) # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "dXADn7KYRWV3",
    "outputId": "9a348092-f676-4240-ba78-1f1fc6197d7b"
   },
   "outputs": [],
   "source": [
    "# Validate (JUST RUN THE CODE)\n",
    "X_train_concat_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5D3MxPmReOv"
   },
   "source": [
    "- And finally, we standardize the data so that it can perform well during model optimization (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7Jq_KCcBMBu"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create two functions to perform scaling & transform scaling\n",
    "# The scaling is Standardization\n",
    "# The first function is to fit the scaler, called by fit_scaler\n",
    "# - You need an input, a data (pd.Dataframe)\n",
    "# - You create a standardization scaler (please use sklearn)\n",
    "# - Your output is the scaler\n",
    "#\n",
    "# The second function is to transform data using scaler, called by transform_scaler\n",
    "# - There are two inputs, a data (pd.Dataframe), a scaler (sklearn object)\n",
    "# - You scaled the data, then return the scaled data\n",
    "# Write your code here\n",
    "####################################################\n",
    "def fit_scaler(data):\n",
    "    \"\"\"\n",
    "    Fit a StandardScaler to the given data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input data to fit the scaler.\n",
    "        \n",
    "    Returns:\n",
    "    - StandardScaler: The fitted scaler.\n",
    "    \"\"\"\n",
    "    fit_data = StandardScaler().fit(data)\n",
    "\n",
    "    return fit_data\n",
    "\n",
    "def transform_scaler(data, scaled):\n",
    "    \"\"\"\n",
    "    Transform the given data using the fitted scaler.\n",
    "    \n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input data to be transformed.\n",
    "    - scaled (StandardScaler): The fitted scaler.\n",
    "        \n",
    "    Returns:\n",
    "    - pd.DataFrame: Scaled data in the same format as the input DataFrame.\n",
    "    \"\"\"\n",
    "    transformed_data = scaled.transform(data)\n",
    "    transform_data = pd.DataFrame(transformed_data, columns=data.columns, index=data.index)\n",
    "\n",
    "    return transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler\n",
    "scaler = fit_scaler(X_train_concat_fe) # WRITE YOUR CODE HERE\n",
    "\n",
    "# Transform the scaler\n",
    "X_train_clean = transform_scaler(X_train_concat_fe, scaler) # WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "OLeIPoDGTIlc",
    "outputId": "347126f6-54f4-4c34-dab0-d91aa81a2c61"
   },
   "outputs": [],
   "source": [
    "# Validate (JUST RUN THE CODE)\n",
    "X_train_clean.describe().round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiJ-dDJ98ktg"
   },
   "source": [
    "Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oQY9GhDTUpI"
   },
   "source": [
    "#### 2.9. Create the preprocess function (10 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08Q3aT2KTUpW"
   },
   "source": [
    "- Now, let's create a function to preprocess other set of data (valid & test) so that we can predict that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nle2MYzV2crW"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create a function to preprocess the dataset\n",
    "# You called the function preprocess_data\n",
    "# - It needs many input\n",
    "#   - data, pd.DataFrame\n",
    "#   - num_cols, the numerical columns, list\n",
    "#   - cat_cols, the categorical columns, list\n",
    "#   - num_imputer, the numerical imputer, sklearn object\n",
    "#   - cat_imputer, the categorical imputer, sklearn object\n",
    "#   - cat_encoder, the categorical encoder, sklearn object\n",
    "#   - scaler, the data scaler, sklearn object\n",
    "# - You preprocess the data following step 2.3 - 2.8\n",
    "# - You return the clean data\n",
    "#\n",
    "# Write your code here\n",
    "####################################################\n",
    "def preprocess_data(data, num_cols, cat_cols, num_imputer, cat_imputer, cat_encoder, scaler):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by imputing missing values, encoding categorical variables, and scaling numerical variables.\n",
    "\n",
    "    Parameters:\n",
    "    - data: pd.DataFrame, the input data.\n",
    "    - num_cols: list, the numerical columns.\n",
    "    - cat_cols: list, the categorical columns.\n",
    "    - num_imputer: sklearn object, the numerical imputer.\n",
    "    - cat_imputer: sklearn object, the categorical imputer.\n",
    "    - cat_encoder: sklearn object, the categorical encoder.\n",
    "    - scaler: sklearn object, the data scaler.\n",
    "\n",
    "    Returns:\n",
    "    - clean_data: pd.DataFrame, the preprocessed data.\n",
    "    \"\"\"\n",
    "    # Validate that the input columns exist in the DataFrame\n",
    "    for col in num_cols + cat_cols:\n",
    "        if col not in data.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in the input DataFrame.\")\n",
    "\n",
    "    # Validate that there is no overlap between numerical and categorical columns\n",
    "    overlap = set(num_cols).intersection(set(cat_cols))\n",
    "    if overlap:\n",
    "        raise ValueError(f\"Columns {overlap} are present in both numerical and categorical lists.\")\n",
    "\n",
    "    # Split the data into numerical and categorical DataFrames\n",
    "    X_train_num = data[num_cols]\n",
    "    X_train_cat = data[cat_cols]\n",
    "\n",
    "    # Fit a numerical features imputer\n",
    "    num_imputed = pd.DataFrame(num_imputer.transform(X_train_num),\n",
    "                                  columns=X_train_num.columns, index=X_train_num.index)\n",
    "    print(f'Numerical data shape  : {num_imputed.shape}')\n",
    "    \n",
    "    #  Fit a categorical features imputer\n",
    "    cat_imputed = pd.DataFrame(cat_imputer.transform(X_train_cat),\n",
    "                                  columns=X_train_cat.columns, \n",
    "                                  index=X_train_cat.index)\n",
    "\n",
    "    # Create a one-hot-encoder for the categorical features\n",
    "    cat_encoded = pd.DataFrame(cat_encoder.transform(cat_imputed), columns=cat_encoder.categories_[0])\n",
    "    cat_encoded.index = cat_imputed.index \n",
    "    print(f'Categorical data shape: {cat_encoded.shape}')\n",
    "\n",
    "    # Join / concat the data\n",
    "    concated_data = pd.concat([num_imputed, cat_encoded], axis=1)\n",
    "    print(f'Concat data shape     : {concated_data.shape}\\n')\n",
    "    \n",
    "    print(f'Original data shape: {concated_data.shape}')\n",
    "\n",
    "    # Create a better feature to summarize the pickup and dropoff coordinate.\n",
    "    concated_data['distance'] = np.sqrt(\n",
    "        (concated_data['dropoff_latitude'] - concated_data['pickup_latitude'])**2 +\n",
    "        (concated_data['dropoff_longitude'] - concated_data['pickup_longitude'])**2\n",
    "    )\n",
    "\n",
    "    concated_data.drop(columns=['dropoff_latitude','pickup_latitude','dropoff_longitude','pickup_longitude'], inplace=True)\n",
    "\n",
    "    # Standardize the data so that it can perform well during model optimization\n",
    "    clean_data = pd.DataFrame(scaler.transform(concated_data), columns=concated_data.columns, index=concated_data.index)\n",
    "    print(f'Mapped data shape  : {clean_data.shape}\\n')\n",
    "        \n",
    "    return clean_data\n",
    "\n",
    "num_cols = ['pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','passenger_count']\n",
    "cat_cols = ['pickup_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQ-MKqkLFgOD",
    "outputId": "8318bbfd-1f49-43a7-e187-fc9f523df746"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data training again\n",
    "X_train_clean = preprocess_data(data=X_train,\n",
    "                                num_cols=num_cols, \n",
    "                                cat_cols=cat_cols, \n",
    "                                num_imputer=num_imputer, \n",
    "                                cat_imputer=cat_imputer, \n",
    "                                cat_encoder=cat_encoder, \n",
    "                                scaler=scaler) # WRITE YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6eSeFeQ5GDWb",
    "outputId": "3cf2ef0c-719f-4337-a188-d6cee615ee42"
   },
   "outputs": [],
   "source": [
    "# Validate (JUST RUN THE CODE)\n",
    "print('Original data shape:', X_train.shape)\n",
    "print('Cleaned data shape :', X_train_clean.shape)\n",
    "X_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_FpyWgVU5GH",
    "outputId": "5ee99cbd-959b-4934-ca11-04878a157ad7"
   },
   "outputs": [],
   "source": [
    "# Transform other set of data\n",
    "X_valid_clean = preprocess_data(data=X_valid,\n",
    "                                num_cols=num_cols, \n",
    "                                cat_cols=cat_cols, \n",
    "                                num_imputer=num_imputer, \n",
    "                                cat_imputer=cat_imputer, \n",
    "                                cat_encoder=cat_encoder, \n",
    "                                scaler=scaler)# WRITE YOUR CODE HERE\n",
    "X_test_clean = preprocess_data(data=X_test,\n",
    "                                num_cols=num_cols, \n",
    "                                cat_cols=cat_cols, \n",
    "                                num_imputer=num_imputer, \n",
    "                                cat_imputer=cat_imputer, \n",
    "                                cat_encoder=cat_encoder, \n",
    "                                scaler=scaler)# WRITE YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9urW_teAVgRu"
   },
   "source": [
    "### 3. Training Machine Learning Models (40 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZQBCdRAVVgRv"
   },
   "source": [
    "```\n",
    "3.1 Prepare train & evaluate model function\n",
    "3.2 Train & evaluate several models\n",
    "3.3 Choose the best model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oh66SXYnWcYo"
   },
   "source": [
    "#### 3.1. Preprare train & evaluate model function (10 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSqSP6iyWiYf"
   },
   "source": [
    "- Before modeling, let's prepare function to train & evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PXun1F0IWfjf"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# First, create a function to train model called train_model\n",
    "# - It needs 3 input\n",
    "#   - estimator, the model (sklearn model)\n",
    "#   - X_train, the input (pd.DataFrame)\n",
    "#   - y_train, the output (pd.DataFrame)\n",
    "# - You only fit the estimator using the X_train & y_train\n",
    "# - Then return nothing\n",
    "#\n",
    "# Next, create a function to evaluate model called evaluate_model\n",
    "# - It needs 5 input\n",
    "#   - estimator, the model (sklearn model)\n",
    "#   - X_train, the train input (pd.DataFrame)\n",
    "#   - y_train, the train output (pd.DataFrame)\n",
    "#   - X_valid, the valid input (pd.DataFrame)\n",
    "#   - y_valid, the valid output (pd.DataFrame)\n",
    "# - You calculate the model performance using root mean squared error metrics\n",
    "# - Then return two output, rmse_train and rmse_valid\n",
    "#\n",
    "# Write your code here\n",
    "####################################################\n",
    "def train_model(estimator, X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train the model on the training data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: sklearn model, the model to be trained.\n",
    "    - X_train: pd.DataFrame, the training input data.\n",
    "    - y_train: pd.Series, the training target data.\n",
    "    \"\"\"\n",
    "    estimator.fit(X_train, y_train)\n",
    "\n",
    "def evaluate_model(estimator, X_train, y_train, X_valid, y_valid):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the training and test data.\n",
    "\n",
    "    Parameters:\n",
    "    - model: sklearn model, the trained model.\n",
    "    - X_train: pd.DataFrame, the training input data.\n",
    "    - y_train: pd.Series, the training target data.\n",
    "    - X_test: pd.DataFrame, the test input data.\n",
    "    - y_test: pd.Series, the test target data.\n",
    "\n",
    "    Returns:\n",
    "    - rmse_train: float, the RMSE on the training data.\n",
    "    - rmse_test: float, the RMSE on the test data.\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    y_train_pred = estimator.predict(X_train)\n",
    "    y_valid_pred = estimator.predict(X_valid)\n",
    "    \n",
    "    # Calculate RMSE for training data\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    \n",
    "    # Calculate RMSE for validation data\n",
    "    rmse_valid = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
    "    \n",
    "    return rmse_train, rmse_valid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBXTMmkaZHfo"
   },
   "source": [
    "#### 3.2. Train and Evaluate Several Models (10 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwv-WpIvZHfp"
   },
   "source": [
    "- Now, let's train & evaluate several models\n",
    "- You should check, which one of the following model is the best model\n",
    "\n",
    "  1. Baseline model\n",
    "  2. k-NN with k=1\n",
    "  3. k-NN with k=100\n",
    "  4. k-NN with k=200\n",
    "  5. k-NN with k=500\n",
    "  6. k-NN with k=len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZELHor_ZHfp"
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "# Create your model here (no need to create function)\n",
    "# Write your code here\n",
    "####################################################\n",
    "reg_1 = DummyRegressor(strategy='mean')               # Write your code here, follow the description\n",
    "reg_2 = KNeighborsRegressor(n_neighbors=1)            # Write your code here, follow the description\n",
    "reg_3 = KNeighborsRegressor(n_neighbors=100)          # Write your code here, follow the description\n",
    "reg_4 = KNeighborsRegressor(n_neighbors=200)          # Write your code here, follow the description\n",
    "reg_5 = KNeighborsRegressor(n_neighbors=500)          # Write your code here, follow the description\n",
    "reg_6 = KNeighborsRegressor(n_neighbors=len(X_test_clean))         # Write your code here, follow the description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HElSDZRbZFOR"
   },
   "outputs": [],
   "source": [
    "# Train the model (JUST RUN THE CODE)\n",
    "train_model(reg_1, X_train_clean, y_train)\n",
    "train_model(reg_2, X_train_clean, y_train)\n",
    "train_model(reg_3, X_train_clean, y_train)\n",
    "train_model(reg_4, X_train_clean, y_train)\n",
    "train_model(reg_5, X_train_clean, y_train)\n",
    "train_model(reg_6, X_train_clean, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EK0Wkx66aRh8",
    "outputId": "3526563f-9bb3-4902-c2eb-5c57fd1c995f"
   },
   "outputs": [],
   "source": [
    "# Return validation (JUST RUN THE CODE)\n",
    "import time\n",
    "\n",
    "for reg in [reg_1, reg_2, reg_3, reg_4, reg_5, reg_6]:\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Generate the rmse\n",
    "    rmse_train, rmse_valid = evaluate_model(estimator=reg,\n",
    "                                            X_train=X_train_clean,\n",
    "                                            y_train=y_train,\n",
    "                                            X_valid=X_valid_clean,\n",
    "                                            y_valid=y_valid)\n",
    "\n",
    "    # Logging\n",
    "    elapsed = time.time() - t0\n",
    "    print(f'model : {str(reg):40s} '\n",
    "          f'| RMSE train: {rmse_train:.4f} '\n",
    "          f'| RMSE valid: {rmse_valid:.4f} '\n",
    "          f'| Time elapsed: {elapsed*1000:.2f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER-CnCxlePhg"
   },
   "source": [
    "#### 3.3. Choose the best model (20 pts)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neVBHKi3ePhh"
   },
   "source": [
    "From the previous results, which one is the best model? (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpOAgKZDeZzp"
   },
   "source": [
    "```\n",
    "model : KNeighborsRegressor(n_neighbors=100)     | RMSE train: 3.9594 | RMSE valid: 3.9783 | Time elapsed: 78513.55 ms\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzZAZgtpegYd"
   },
   "source": [
    "Why do you choose that model? (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtWV7CLhejjV"
   },
   "source": [
    "```\n",
    "Because this model has a good balance between training and validation RMSE, with a relatively low RMSE on both datasets.\n",
    "  - Lowest validation RMSE\n",
    "  - Very small gap between train and valid RMSE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVZMoBjVetmx"
   },
   "source": [
    "And, create a `reg_best` to store the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iYbdAYmNe0B9"
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "reg_best = KNeighborsRegressor(n_neighbors=100) \n",
    "reg_best.fit(X_train_clean, y_train) # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq6iq5FwesuD"
   },
   "source": [
    "### 4. Predictions & Evaluations (JUST RUN THE CODE)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "So1UmURDesuD"
   },
   "source": [
    "```\n",
    "4.1 Predict & Evaluate on the Train Data\n",
    "4.2 Predict & Evaluate on the Test Data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_qdHfkefA9I"
   },
   "source": [
    "#### 4.1. Predict & evaluate on train data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W_Tkv1IifKZd"
   },
   "outputs": [],
   "source": [
    "# Predict (JUST RUN THE CODE)\n",
    "y_train_pred = reg_best.predict(X_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "Xd-YpUxnfRAL",
    "outputId": "952d669b-29cf-4147-cb1d-071c0e109061"
   },
   "outputs": [],
   "source": [
    "# Visualize & compare the prediction (JUST RUN THE CODE)\n",
    "plt.scatter(y_train, y_train_pred)\n",
    "\n",
    "plt.plot([0, 200], [0, 200], c='red')\n",
    "plt.xlim(0, 200); plt.ylim(0, 200)\n",
    "plt.xlabel('y actual'); plt.ylabel('y predicted')\n",
    "plt.title('Comparison of y actual vs y predicted on Train Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4V7-VcNfz02"
   },
   "source": [
    "#### 4.2. Predict & evaluate on test data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNlcNnQIfz03"
   },
   "outputs": [],
   "source": [
    "# Predict (JUST RUN THE CODE)\n",
    "y_test_pred = reg_best.predict(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "l3QE1IeTfz03",
    "outputId": "1a2e7e38-7ab1-443a-f843-39bcb1cd2b50"
   },
   "outputs": [],
   "source": [
    "# Visualize & compare the prediction (JUST RUN THE CODE)\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "\n",
    "plt.plot([0, 200], [0, 200], c='red')\n",
    "plt.xlim(0, 200); plt.ylim(0, 200)\n",
    "plt.xlabel('y actual'); plt.ylabel('y predicted')\n",
    "plt.title('Comparison of y actual vs y predicted on Test Data')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "0le3bfkbsWCu",
    "4VF3H55TwV1f",
    "VPfdLquFzsoI",
    "x_OE7Mklz1Ci",
    "2OzWPGFk3iwl",
    "MPzQ-1Wz3lgP",
    "zO3YDDwc5qQ-",
    "wZ5rwYBA88lQ",
    "TSolzD9z_NOc",
    "tUARDkuwIm7D",
    "1dyVifNK2fZA",
    "ICQiqto83TQ9",
    "e4PGfH5-7QRM",
    "VD93lAeX8ktW",
    "3oQY9GhDTUpI",
    "9urW_teAVgRu",
    "Oh66SXYnWcYo",
    "eBXTMmkaZHfo",
    "ER-CnCxlePhg",
    "cq6iq5FwesuD",
    "u_qdHfkefA9I",
    "Q4V7-VcNfz02"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
